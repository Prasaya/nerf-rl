<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Synthetic 3D Environment Navigation using 
    NeRF-Enhanced Reinforcement Learning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Synthetic 3D Environment Navigation using 
              NeRF-Enhanced Reinforcement Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block" style="margin-right: 2pt">
                <b>Prasaya Acharya</a>, </span>
                <span class="author-block" style="margin-right: 2pt;"">
                  Suven Pandey</a>, </span>
                  <span class="author-block">
                    Suprim Shrestha</b>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">IOE Thapathali Campus<br>Thapathali Graduate Conference<br>Eastern European Machine Learning Summer School 2024 (To Present)</span></span>
                  </div>

                  <!-- <div class="column has-text-centered"> -->
                    <!-- <div class="publication-links">
                         
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    Supplementary PDF link
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  Github link
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                ArXiv abstract Link
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span> -->
                <!-- </a>
              </span>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <!-- Paper video. -->
      <h2 class="title is-3">Results</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/1WhISOPqpLM?si=l1TgHT5DkyRcHnpK" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
         Your video here 
        <source src="static/videos/major_project.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This project explores the simulation of humanoid agents navigating within photorealistic, 
synthetic 3D environments using a combination of Neural Radiance Fields (NeRF) and Reinforcement 
Learning (RL). We first capture a real-world scene using multiple high-resolution images and utilize NeRF 
to reconstruct the environment as a continuous function, enabling novel viewpoint generation. To facilitate 
agent interaction, we extract a mesh representation from the NeRF volume and integrate it into a physics 
simulator. A humanoid agent is then trained using Proximal Policy Optimization (PPO) with a reward 
structure encouraging forward movement and obstacle avoidance. However, this approach results in unnatural 
gait patterns. To address this, we incorporate imitation learning, to mimic natural human locomotion. Finally, 
we generate a unified video by overlaying the agent's movement within the physics engine onto a video 
rendered from the NeRF representation, showcasing the agent's navigation in a photorealistic and visually 
appealing manner. Our approach demonstrates the effectiveness of combining Neural Radiance Fields and 
Reinforcement Learning for creating interactive and realistic virtual environments for embodied AI agents.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       
       
        <div class="item" >
        <!-- Your image here -->
        <img src="static/images/figure1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br><br>
          <b>Figure 1:</b> Overview of the proposed pipeline. First, we collect a set of images of the scene using a smartphone camera. Second, we use 
structure-from-motion software to determine camera poses. Third, we train a NeRF on these labeled images. Then, we extract the mesh from 
the NeRF. We import the mesh of the scene along with mesh of obstacles into the physics simulator and train the agent to evade these 
obstacles using reinforcement learning. We capture a video of the agent completing the course and record the camera positions. We render 
the video from NeRF using the recorded camera positions and combine the two videos to get the final combined video.
        </h2>
      </div>
      
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figure2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br><br>
          <b>Figure 2:</b> Pipeline for mesh generation from NeRF model. Camera 
positions are extracted from the input images using COLMAP, and 
used for training the NeRF model from which a mesh is extracted.
        </h2>
      </div>
      
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/figure3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          <br><br>
          <b>Figure 3: </b> Figure illustrates the stepwise process of mesh extraction: first figure shows 3D point cloud and camera positions, second shows
          NeRF model output, and the third shows extracted mesh.
       </h2>
     </div>
     
     
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/figure4.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <br><br>
        <b>Figure 4:</b> The first figure shows the 3D point cloud for an outdoor scene. The second figure shows a novel view generated by our model. 
The figure shows the comparison between the ground truth (left) and rendering from NeRF (right).
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/figure5.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered" >
        <br>
        <b>Figure 5:</b> Figure shows the training of agent and generation of video. (a) Mesh generated using pipeline in Figure 2. (b) Synthetic environment 
with obstacles. (c) Agent at the start of obstacle course. (d) Agent learning to navigate in the simulated environment. (e) All objects except 
the agent and the obstacles are replaced with a green background. (f) Final combined video of agent navigating through NeRF rendered 
environment
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
           
            <iframe src="https://www.youtube.com/embed/1WhISOPqpLM?si=l1TgHT5DkyRcHnpK" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->



<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Coming Soon</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
